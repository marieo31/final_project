{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle different types of transformation\n",
    "# different nb of pixels\n",
    "# different nb of level of gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MariO\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# from sklearn import tree\n",
    "import os\n",
    "import random\n",
    "\n",
    "mpl.rc('image', cmap='gray_r')\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot90ccw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg counter clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, 1],\n",
    "               [-1,0]])\n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][0] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot\n",
    "\n",
    "def rot90cw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, -1],\n",
    "               [1,0]])    \n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][1] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation matrices\n",
    "def create_PPstar_translation(nbpix):\n",
    "    # nb of pixels translated\n",
    "    nbt = int(np.round(0.25*nbpix))\n",
    "\n",
    "    # bottom left square block\n",
    "    bl = np.eye(nbpix-nbt,nbpix-nbt)\n",
    "    # upper right square block\n",
    "    ur = np.eye(nbt,nbt)\n",
    "    # upper left rect block\n",
    "    ul = np.zeros((nbt,nbpix-nbt))\n",
    "    # bottom right rect block\n",
    "    br = np.zeros((nbpix-nbt,nbt))\n",
    "\n",
    "    # concatenate the blocks to build the transformation matrix\n",
    "    P = np.concatenate((np.concatenate((ul,ur), axis=1), np.concatenate((bl,br), axis=1)), axis=0)\n",
    "    Pstar = np.linalg.inv(P)        \n",
    "    return (P,Pstar)\n",
    "\n",
    "def translate2left(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@P\n",
    "def translate2right(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@Pstar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "def remove_ticks():\n",
    "    plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    labelleft=False,\n",
    "    labelbottom=False) # labels along the bottom edge are off    \n",
    "    return\n",
    "\n",
    "def vis_matrices(Mr, Mm, Mst, MstM):\n",
    "#     print(Mr.shape[0])\n",
    "    if Mr.shape[0]==1:\n",
    "        Mr = Mr.reshape(int(np.sqrt(Mr.shape[1])), int(np.sqrt(Mr.shape[1])))\n",
    "        Mm = Mm.reshape(int(np.sqrt(Mm.shape[1])), int(np.sqrt(Mm.shape[1])))\n",
    "        Mst = Mst.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "        MstM = MstM.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=2,ncols=2) #, squeeze=True, sharey=True)\n",
    "    fig.set_size_inches(8,8)\n",
    "\n",
    "    plt.sca(ax1[0])\n",
    "    plt.imshow(Mr)\n",
    "    plt.title(\"Real image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[0])\n",
    "    plt.imshow(Mm)\n",
    "    plt.title(\"Distorted image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax1[1])\n",
    "    plt.imshow(Mst)\n",
    "    plt.title(\"Corrected input\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[1])\n",
    "    plt.imshow(MstM)\n",
    "    plt.title(\"Corrected visualization\")\n",
    "    remove_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(nbpix,transform_type):\n",
    "    \"\"\"\n",
    "    Build the set of one pixel matrices and apply the transformations\n",
    "    \"\"\"\n",
    "    # List of indexes where to put a black pixel\n",
    "    idx = range(0,nbpix**2,1)\n",
    "\n",
    "    # Initialize empty arrays \n",
    "    Mreal_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mmang_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mstar_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    for ii in idx:\n",
    "        # Fill the indexed pixel with a one\n",
    "        Mreal_tab[ii,ii] = 1\n",
    "        # Use the transformation matrices to generate Mmang and Mstar\n",
    "#         Mmang_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@P).reshape(1,nbpix**2)\n",
    "#         Mstar_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@Pstar).reshape(1,nbpix**2)\n",
    "            \n",
    "        if transform_type is \"translation\":    \n",
    "            Mmang_tab[ii,:] = translate2left(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = translate2right(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "        elif transform_type is \"rotation\":\n",
    "            Mmang_tab[ii,:] = rot90ccw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = rot90cw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            \n",
    "    return (Mreal_tab, Mmang_tab, Mstar_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add one on the designated index\n",
    "def add_one(arr,index):\n",
    "    arr[0,index] = 1\n",
    "    return arr\n",
    "\n",
    "# Function to split the matrix into matrices of one pixel\n",
    "def split_matrix(mat):\n",
    "    \"\"\" Split a matrix into matrices of one pixel\"\"\"\n",
    "    # find the indexes of the ones values in the matrix\n",
    "#     idx_arr = np.where(mat.reshape(1,nbpix**2)[0]==1)[0]\n",
    "    idx_arr = np.where(mat.reshape(1,nbpix**2)[0]>0)[0]\n",
    "    # transform from an array to a list\n",
    "    idx_lst = [idx_arr.item(ii) for ii in range(0,len(idx_arr))] \n",
    "    temp = np.zeros((1,nbpix**2))\n",
    "    mat_split = np.zeros((len(idx_lst), nbpix**2))\n",
    "#     Mtest = np.zeros((nbpix,nbpix))\n",
    "    for ii in range(0,len(idx_lst)):\n",
    "        mat_split[ii,idx_lst[ii]] = 1    \n",
    "#         Mtest = Mtest + Mreal_split[ii,:].reshape(nbpix,nbpix)\n",
    "    return mat_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction functions\n",
    "def perform_prediction(mat, model):\n",
    "    \"\"\" Predict the output with a trained model\"\"\"\n",
    "    # split the input matrix into matrices of one pixel\n",
    "    mat_split = split_matrix(mat)\n",
    "    nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "    # initializations\n",
    "    res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "    Mres = np.zeros((nbpix,nbpix))\n",
    "    # Loop on all the one pixels array\n",
    "    for ii in range(0,nb_dark_pxl):\n",
    "        # Apply the models to the one pixel matrices\n",
    "#         print(mat_split[ii])\n",
    "        res[ii,:] = model.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "        # Sum up the results to construct the matrices\n",
    "        Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "    return Mres\n",
    "\n",
    "# def predict_corrector(mat):\n",
    "#     # split the input matrix into matrices of one pixel\n",
    "#     mat_split = split_matrix(mat)\n",
    "#     nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "#     # initializations\n",
    "#     res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "#     Mres = np.zeros((nbpix,nbpix))\n",
    "#     # Loop on all the one pixels array\n",
    "#     for ii in range(0,nb_dark_pxl):\n",
    "#         # Apply the models to the one pixel matrices\n",
    "#         res[ii,:] = model_corrector.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "#         # Sum up the results to construct the matrices\n",
    "#         Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "#     return Mres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_door_img(nbpix):\n",
    "    \"\"\" Create an nbpix by nbpix image of a door\"\"\"\n",
    "    nbborder = int(np.round(nbpix*0.3))\n",
    "    u = np.ones((nbborder,nbpix))\n",
    "    l = np.ones((nbpix-nbborder,nbborder))\n",
    "    r = l\n",
    "    door = np.zeros((nbpix-nbborder, nbpix-2*nbborder))\n",
    "\n",
    "    return np.concatenate((u,np.concatenate((l,door,r), axis=1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def grayscale_cmap(cmap):\n",
    "#     \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "#     cmap = plt.cm.get_cmap(cmap)\n",
    "#     colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "#     # convert RGBA to perceived grayscale luminance\n",
    "#     # cf. http://alienryderflex.com/hsp.html\n",
    "#     RGB_weight = [0.299, 0.587, 0.114]\n",
    "#     luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "#     colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "#     return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)\n",
    "\n",
    "# mpl.rc('image', cmap=grayscale_cmap(\"viridis_r\"))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nbpix = 4 # nb of pixel to consider (nbpix x nbpix)\n",
    "transform_type = \"rotation\" # type of transformation : \"translation\" or \"rotation\"\n",
    "training_type = \"full\" # type of training: \"partial\" of \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformation matrices\n",
    "\n",
    "# import random\n",
    "# (P,Pstar) = create_PPstar(nbpix)\n",
    "\n",
    "# Create the training data\n",
    "(Mreal_tab, Mmang_tab, Mstar_tab) = create_training_data(nbpix,transform_type)\n",
    "\n",
    "\n",
    "# the training input are the matrices of the real images with one pixel\n",
    "\n",
    "if training_type is \"partial\": # we remove randomly 20% of the training data\n",
    "    # rebuild the list of indexes and shuffle it\n",
    "    rdm_idx = list(range(0,nbpix**2,1))\n",
    "    random.shuffle(rdm_idx)\n",
    "    \n",
    "    # remove 80% of the indexes of this list\n",
    "    rdm_idx[0:int(np.round(nbpix**2*0.8))] = []\n",
    "    \n",
    "    # delete the corresponding rows in the training matrices\n",
    "    Mreal_tab = np.delete(Mreal_tab, rdm_idx, axis=0)\n",
    "    Mmang_tab = np.delete(Mmang_tab, rdm_idx, axis=0)\n",
    "    Mstar_tab = np.delete(Mstar_tab, rdm_idx, axis=0)\n",
    "    \n",
    "    print(f\"Training performed on {Mreal_tab.shape[0]}/{Mreal_tab.shape[1]} pixels\")\n",
    "\n",
    "idx = range(0,Mreal_tab.shape[0],1)        \n",
    "X_train = Mreal_tab   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.5877 - acc: 0.0278\n",
      "Epoch 2/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5535 - acc: 0.1111\n",
      "Epoch 3/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.5275 - acc: 0.2222\n",
      "Epoch 4/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.5056 - acc: 0.2222\n",
      "Epoch 5/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4837 - acc: 0.3333\n",
      "Epoch 6/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4619 - acc: 0.3889\n",
      "Epoch 7/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4405 - acc: 0.5833\n",
      "Epoch 8/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4190 - acc: 0.6389\n",
      "Epoch 9/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3973 - acc: 0.6667\n",
      "Epoch 10/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.3758 - acc: 0.7500\n",
      "Epoch 11/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.3529 - acc: 0.7778\n",
      "Epoch 12/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.3299 - acc: 0.8333\n",
      "Epoch 13/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3047 - acc: 0.8889\n",
      "Epoch 14/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.2803 - acc: 0.9167\n",
      "Epoch 15/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.2555 - acc: 0.9167\n",
      "Epoch 16/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.2298 - acc: 0.9167\n",
      "Epoch 17/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 3.2023 - acc: 0.9167\n",
      "Epoch 18/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1738 - acc: 0.9444\n",
      "Epoch 19/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1443 - acc: 0.9722\n",
      "Epoch 20/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1136 - acc: 0.9722\n",
      "Epoch 21/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.0811 - acc: 0.9722\n",
      "Epoch 22/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 3.0477 - acc: 1.0000\n",
      "Epoch 23/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.0124 - acc: 1.0000\n",
      "Epoch 24/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9769 - acc: 1.0000\n",
      "Epoch 25/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9401 - acc: 1.0000\n",
      "Epoch 26/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.9015 - acc: 1.0000\n",
      "Epoch 27/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.8615 - acc: 1.0000\n",
      "Epoch 28/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.8183 - acc: 1.0000\n",
      "Epoch 29/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.7715 - acc: 1.0000\n",
      "Epoch 30/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.7267 - acc: 1.0000\n",
      "Epoch 31/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.6773 - acc: 1.0000\n",
      "Epoch 32/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.6276 - acc: 1.0000\n",
      "Epoch 33/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.5761 - acc: 1.0000\n",
      "Epoch 34/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 2.5237 - acc: 1.0000\n",
      "Epoch 35/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.4711 - acc: 1.0000\n",
      "Epoch 36/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.4130 - acc: 1.0000\n",
      "Epoch 37/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.3562 - acc: 1.0000\n",
      "Epoch 38/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 2.2967 - acc: 1.0000\n",
      "Epoch 39/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.2336 - acc: 1.0000\n",
      "Epoch 40/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.1708 - acc: 1.0000\n",
      "Epoch 41/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.1050 - acc: 1.0000\n",
      "Epoch 42/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.0392 - acc: 1.0000\n",
      "Epoch 43/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.9592 - acc: 1.000 - 0s 417us/step - loss: 1.9707 - acc: 1.0000\n",
      "Epoch 44/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 1.9028 - acc: 1.0000\n",
      "Epoch 45/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.8340 - acc: 1.0000\n",
      "Epoch 46/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.7624 - acc: 1.0000\n",
      "Epoch 47/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.6933 - acc: 1.0000\n",
      "Epoch 48/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 1.6219 - acc: 1.0000\n",
      "Epoch 49/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.5512 - acc: 1.0000\n",
      "Epoch 50/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.4787 - acc: 1.0000\n",
      "Epoch 51/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.4061 - acc: 1.0000\n",
      "Epoch 52/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.3347 - acc: 1.0000\n",
      "Epoch 53/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.2669 - acc: 1.0000\n",
      "Epoch 54/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.1962 - acc: 1.0000\n",
      "Epoch 55/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 1.1316 - acc: 1.0000\n",
      "Epoch 56/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.0672 - acc: 1.0000\n",
      "Epoch 57/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.0010 - acc: 1.0000\n",
      "Epoch 58/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.9394 - acc: 1.0000\n",
      "Epoch 59/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.8800 - acc: 1.0000\n",
      "Epoch 60/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.8210 - acc: 1.0000\n",
      "Epoch 61/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.7642 - acc: 1.0000\n",
      "Epoch 62/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.7107 - acc: 1.0000\n",
      "Epoch 63/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.6609 - acc: 1.0000\n",
      "Epoch 64/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.6119 - acc: 1.0000\n",
      "Epoch 65/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.5676 - acc: 1.0000\n",
      "Epoch 66/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 67/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.4860 - acc: 1.0000\n",
      "Epoch 68/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4507 - acc: 1.0000\n",
      "Epoch 69/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.4166 - acc: 1.0000\n",
      "Epoch 70/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 71/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 72/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.3317 - acc: 1.0000\n",
      "Epoch 73/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3078 - acc: 1.0000\n",
      "Epoch 74/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2870 - acc: 1.0000\n",
      "Epoch 75/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.2672 - acc: 1.0000\n",
      "Epoch 76/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.2490 - acc: 1.0000\n",
      "Epoch 77/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2330 - acc: 1.0000\n",
      "Epoch 78/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 79/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.2039 - acc: 1.0000\n",
      "Epoch 80/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 81/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.1789 - acc: 1.0000\n",
      "Epoch 82/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1676 - acc: 1.0000\n",
      "Epoch 83/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 84/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1484 - acc: 1.0000\n",
      "Epoch 85/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1397 - acc: 1.0000\n",
      "Epoch 86/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.1320 - acc: 1.0000\n",
      "Epoch 87/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 88/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.1188 - acc: 1.0000\n",
      "Epoch 89/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 90/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 91/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 92/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0981 - acc: 1.0000\n",
      "Epoch 93/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 94/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 95/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 96/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0821 - acc: 1.0000\n",
      "Epoch 97/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 98/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 99/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0730 - acc: 1.0000\n",
      "Epoch 100/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 101/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 102/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 103/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 104/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 105/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 106/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 107/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 108/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 109/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 110/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 111/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 112/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 113/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 114/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 115/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 116/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 117/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 118/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 119/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 120/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 121/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 122/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 123/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 124/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 125/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 126/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 127/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 128/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 129/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 130/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 131/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 132/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 133/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 134/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 135/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 136/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 137/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 138/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 139/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 140/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 141/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 142/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 143/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 144/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 145/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 146/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 147/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 148/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 149/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 150/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 151/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0211 - acc: 1.000 - 0s 167us/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 152/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 153/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 154/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 155/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 156/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 157/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 158/180\n",
      "36/36 [==============================] - 0s 694us/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 159/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 160/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 161/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 162/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 163/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 164/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 165/180\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 166/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 167/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 168/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 222us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 169/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 170/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 171/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 172/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 173/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 174/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 175/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 176/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 177/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 178/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 179/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 180/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/180\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.5878 - acc: 0.0000e+00\n",
      "Epoch 2/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5538 - acc: 0.0278\n",
      "Epoch 3/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5294 - acc: 0.0833\n",
      "Epoch 4/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5072 - acc: 0.2500\n",
      "Epoch 5/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.4858 - acc: 0.3611\n",
      "Epoch 6/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4646 - acc: 0.5000\n",
      "Epoch 7/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4456 - acc: 0.5000\n",
      "Epoch 8/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.4255 - acc: 0.5833\n",
      "Epoch 9/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.4042 - acc: 0.6111\n",
      "Epoch 10/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.3834 - acc: 0.7222\n",
      "Epoch 11/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.3622 - acc: 0.8889\n",
      "Epoch 12/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.3397 - acc: 0.9444\n",
      "Epoch 13/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3165 - acc: 0.9444\n",
      "Epoch 14/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.2924 - acc: 0.9722\n",
      "Epoch 15/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.2681 - acc: 1.0000\n",
      "Epoch 16/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.2432 - acc: 1.0000\n",
      "Epoch 17/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.2167 - acc: 1.0000\n",
      "Epoch 18/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1904 - acc: 1.0000\n",
      "Epoch 19/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1617 - acc: 1.0000\n",
      "Epoch 20/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1317 - acc: 1.0000\n",
      "Epoch 21/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 3.0997 - acc: 1.0000\n",
      "Epoch 22/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.0687 - acc: 1.0000\n",
      "Epoch 23/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.0359 - acc: 1.0000\n",
      "Epoch 24/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.0004 - acc: 1.0000\n",
      "Epoch 25/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.9651 - acc: 1.0000\n",
      "Epoch 26/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9262 - acc: 1.0000\n",
      "Epoch 27/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.8868 - acc: 1.0000\n",
      "Epoch 28/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.8453 - acc: 1.0000\n",
      "Epoch 29/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.8012 - acc: 1.0000\n",
      "Epoch 30/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.7561 - acc: 1.0000\n",
      "Epoch 31/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.7095 - acc: 1.0000\n",
      "Epoch 32/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.6622 - acc: 1.0000\n",
      "Epoch 33/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.6125 - acc: 1.0000\n",
      "Epoch 34/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.5606 - acc: 1.0000\n",
      "Epoch 35/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.5070 - acc: 1.0000\n",
      "Epoch 36/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 2.4534 - acc: 1.0000\n",
      "Epoch 37/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.3973 - acc: 1.0000\n",
      "Epoch 38/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.3384 - acc: 1.0000\n",
      "Epoch 39/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.2798 - acc: 1.0000\n",
      "Epoch 40/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.2191 - acc: 1.0000\n",
      "Epoch 41/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.1598 - acc: 1.0000\n",
      "Epoch 42/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.0981 - acc: 1.0000\n",
      "Epoch 43/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.0327 - acc: 1.0000\n",
      "Epoch 44/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.9666 - acc: 1.0000\n",
      "Epoch 45/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.8976 - acc: 1.0000\n",
      "Epoch 46/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.8299 - acc: 1.0000\n",
      "Epoch 47/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.7617 - acc: 1.0000\n",
      "Epoch 48/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.6935 - acc: 1.0000\n",
      "Epoch 49/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.6249 - acc: 1.0000\n",
      "Epoch 50/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.5562 - acc: 1.0000\n",
      "Epoch 51/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.4877 - acc: 1.0000\n",
      "Epoch 52/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.4193 - acc: 1.0000\n",
      "Epoch 53/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.3477 - acc: 1.0000\n",
      "Epoch 54/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.2798 - acc: 1.0000\n",
      "Epoch 55/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.2090 - acc: 1.0000\n",
      "Epoch 56/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.1416 - acc: 1.0000\n",
      "Epoch 57/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.0753 - acc: 1.0000\n",
      "Epoch 58/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0069 - acc: 1.000 - 0s 222us/step - loss: 1.0122 - acc: 1.0000\n",
      "Epoch 59/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.9491 - acc: 1.0000\n",
      "Epoch 60/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.8873 - acc: 1.0000\n",
      "Epoch 61/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.8308 - acc: 1.0000\n",
      "Epoch 62/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.7738 - acc: 1.0000\n",
      "Epoch 63/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.7172 - acc: 1.0000\n",
      "Epoch 64/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.6664 - acc: 1.0000\n",
      "Epoch 65/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.6181 - acc: 1.0000\n",
      "Epoch 66/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.5755 - acc: 1.0000\n",
      "Epoch 67/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 68/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4963 - acc: 1.0000\n",
      "Epoch 69/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4590 - acc: 1.0000\n",
      "Epoch 70/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.4248 - acc: 1.0000\n",
      "Epoch 71/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3929 - acc: 1.0000\n",
      "Epoch 72/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.3622 - acc: 1.0000\n",
      "Epoch 73/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.3328 - acc: 1.0000\n",
      "Epoch 74/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.3072 - acc: 1.0000\n",
      "Epoch 75/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.2833 - acc: 1.0000\n",
      "Epoch 76/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.2607 - acc: 1.0000\n",
      "Epoch 77/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 78/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 79/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.2098 - acc: 1.0000\n",
      "Epoch 80/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 81/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.1827 - acc: 1.0000\n",
      "Epoch 82/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 83/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1597 - acc: 1.0000\n",
      "Epoch 84/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1498 - acc: 1.0000\n",
      "Epoch 85/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 86/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 87/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1265 - acc: 1.0000\n",
      "Epoch 88/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 89/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 90/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 91/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 92/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 93/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 94/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0916 - acc: 1.0000\n",
      "Epoch 95/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 96/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 97/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 98/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 99/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 100/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 101/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 102/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 103/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 104/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 105/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 106/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 107/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 108/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 109/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 110/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 111/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 112/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 113/180\n",
      "36/36 [==============================] - 0s 444us/step - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 114/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 115/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 116/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 117/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 118/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 119/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 120/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 121/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 122/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 123/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 124/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 125/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 126/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 127/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 128/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 129/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 130/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 131/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 132/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 133/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 134/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 135/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 136/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 137/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 138/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 139/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 140/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 141/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 142/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 143/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 144/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 145/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 146/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0229 - acc: 1.000 - 0s 194us/step - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 147/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 148/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 149/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 150/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 151/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 152/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 153/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 154/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 155/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 167us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 156/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 157/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 158/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 159/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 160/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 161/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 162/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 163/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 164/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 165/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 166/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 167/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 168/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 169/180\n",
      "36/36 [==============================] - 0s 528us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 170/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 171/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 172/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 173/180\n",
      "36/36 [==============================] - 0s 444us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 174/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 175/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 176/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 177/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 178/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 179/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 180/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0137 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# the training output will be the category corresponding to the position of the pixel in the mangled image\n",
    "y_train = [np.where(Mmang_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train = to_categorical(y_train, nbpix**2)\n",
    "\n",
    "# or the position of the pixel in the corrected image\n",
    "y_train_cor = [np.where(Mstar_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train_cor = to_categorical(y_train_cor, nbpix**2)\n",
    "\n",
    "# creating the models\n",
    "model_mangler = Sequential()\n",
    "model_mangler.add(Dense(4*nbpix**2, activation='relu', input_dim=nbpix**2))\n",
    "model_mangler.add(Dense(4*nbpix**2, activation='relu'))\n",
    "model_mangler.add(Dense(nbpix**2, activation='softmax'))\n",
    "# Inversion strategy doesnt work very well...\n",
    "# we are going to try using another model, trained on the corrected input.\n",
    "model_corrector = Sequential()\n",
    "model_corrector.add(Dense(4*nbpix**2, activation='relu', input_dim=nbpix**2))\n",
    "model_corrector.add(Dense(4*nbpix**2, activation='relu'))\n",
    "model_corrector.add(Dense(nbpix**2, activation='softmax'))\n",
    "\n",
    "# Compile the models\n",
    "model_mangler.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_corrector.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# train the model \"mangler\"\n",
    "model_mangler.fit( X_train,\n",
    "    y_train,\n",
    "    epochs=5*nbpix**2,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# train the corrected input model\n",
    "model_corrector.fit( X_train,\n",
    "    y_train_cor,\n",
    "    epochs=5*nbpix**2,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")    \n",
    "\n",
    "# model_mangler.summary()\n",
    "# model_corrector.summary()\n",
    "\n",
    "# Save the models\n",
    "model_mangler.save(f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "model_corrector.save(f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the models to an existing image\n",
    "\n",
    "# Load the saved models\n",
    "model_mangler = load_model(f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "model_corrector = load_model(f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mreal = create_door_img(nbpix) \n",
    "cut = 0.5\n",
    "Mreal = np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut])\n",
    "# Mreal_split = split_matrix(Mreal)\n",
    "\n",
    "# Predict the mangled image based on the real one\n",
    "Mmang_ml = perform_prediction(Mreal,model_mangler ) # predict_mangler(Mreal)\n",
    "# Predict the corrected input based on the real image\n",
    "Mcor_ml = perform_prediction(Mreal, model_corrector)# predict_corrector(Mreal)\n",
    "# Prediction of the output from the corrected input\n",
    "Mout_ml = perform_prediction(np.round(Mcor_ml), model_mangler)\n",
    "# plot the results\n",
    "# vis_matrices(Mreal, Mmang_ml,Mcor_ml, Mout_ml)\n",
    "if transform_type is \"translation\":\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, translate2left(Mcor_ml))\n",
    "elif transform_type is \"rotation\":\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, rot90ccw(Mcor_ml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_matrices(Mreal, rot90ccw(Mreal),rot90cw(Mreal), rot90ccw(rot90cw(Mreal)))\n",
    "\n",
    "from flask import jsonify\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import codecs, json \n",
    "\n",
    "a = np.arange(10).reshape(2,5) # a 2 by 5 array\n",
    "b = a.tolist() # nested lists with same data, indices\n",
    "file_path = \"/path.json\" ## your path variable\n",
    "json.dump(b, codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4) ### this saves the array in .json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "{\"mat\": [[0, 0, 0, 1], [0, 0, 1, 1], [1, 1, 0, 0], [0, 0, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape)\n",
    "\n",
    "# json_dump = json.dumps({'a': a, 'aa': [2, (2, 3, 4), a], 'bb': [2]}, cls=NumpyEncoder)\n",
    "json_dump = json.dumps({\"mat\": Mreal}, cls=NumpyEncoder)\n",
    "print(json_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n",
      "{\"a\": [[1, 0, 0, 1], [0, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 1]]}\n"
     ]
    }
   ],
   "source": [
    "cut = 0.5\n",
    "print(nbpix)\n",
    "rmd_img = np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut])\n",
    "print(np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut]))\n",
    "json_dump = json.dumps({\"a\": rmd_img} , cls=NumpyEncoder)\n",
    "print(json_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"{\\\\\"a\\\\\": [[1, 0, 0, 1], [0, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 1]]}\"]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(json_dump).to_json(orient='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayToList(arr):\n",
    "    return [ii.item() for ii in arr.reshape((arr.size,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform into a list\n",
    "mat_list = [ii.item() for ii in Mreal.reshape((nbpix**2,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 0 1 1]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayToList(Mreal)\n",
    "# Mreal.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4,16,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8, 10, 12, 14]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayToList(np.arange(4,16,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "rotation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "nbpixTransformMat = \"4rotation1101110100010001\"\n",
    "nbpix = int(re.search(r'\\d+', nbpixTransformMat).group())\n",
    "print(nbpix)\n",
    "transform_type = ''.join([i for i in nbpixTransformMat if not i.isdigit()])   \n",
    "print(transform_type)\n",
    "training_type = \"full\" # for now we only use fully trained models\n",
    "\n",
    "mat = nbpixTransformMat[-nbpix**2:]\n",
    "\n",
    "input_values = np.asarray([int(mm) for mm in nbpixTransformMat[-nbpix**2:]])\n",
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
