{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle different types of transformation\n",
    "# different nb of pixels\n",
    "# different nb of level of gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MariO\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# from sklearn import tree\n",
    "import os\n",
    "import random\n",
    "\n",
    "mpl.rc('image', cmap='gray_r')\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot90ccw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg counter clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, 1],\n",
    "               [-1,0]])\n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][0] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot\n",
    "\n",
    "def rot90cw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, -1],\n",
    "               [1,0]])    \n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][1] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation matrices\n",
    "def create_PPstar_translation(nbpix):\n",
    "    # nb of pixels translated\n",
    "    nbt = int(np.round(0.25*nbpix))\n",
    "\n",
    "    # bottom left square block\n",
    "    bl = np.eye(nbpix-nbt,nbpix-nbt)\n",
    "    # upper right square block\n",
    "    ur = np.eye(nbt,nbt)\n",
    "    # upper left rect block\n",
    "    ul = np.zeros((nbt,nbpix-nbt))\n",
    "    # bottom right rect block\n",
    "    br = np.zeros((nbpix-nbt,nbt))\n",
    "\n",
    "    # concatenate the blocks to build the transformation matrix\n",
    "    P = np.concatenate((np.concatenate((ul,ur), axis=1), np.concatenate((bl,br), axis=1)), axis=0)\n",
    "    Pstar = np.linalg.inv(P)        \n",
    "    return (P,Pstar)\n",
    "\n",
    "def translate2left(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@P\n",
    "def translate2right(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@Pstar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "def remove_ticks():\n",
    "    plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    labelleft=False,\n",
    "    labelbottom=False) # labels along the bottom edge are off    \n",
    "    return\n",
    "\n",
    "def vis_matrices(Mr, Mm, Mst, MstM):\n",
    "#     print(Mr.shape[0])\n",
    "    if Mr.shape[0]==1:\n",
    "        Mr = Mr.reshape(int(np.sqrt(Mr.shape[1])), int(np.sqrt(Mr.shape[1])))\n",
    "        Mm = Mm.reshape(int(np.sqrt(Mm.shape[1])), int(np.sqrt(Mm.shape[1])))\n",
    "        Mst = Mst.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "        MstM = MstM.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=2,ncols=2) #, squeeze=True, sharey=True)\n",
    "    fig.set_size_inches(8,8)\n",
    "\n",
    "    plt.sca(ax1[0])\n",
    "    plt.imshow(Mr)\n",
    "    plt.title(\"Real image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[0])\n",
    "    plt.imshow(Mm)\n",
    "    plt.title(\"Distorted image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax1[1])\n",
    "    plt.imshow(Mst)\n",
    "    plt.title(\"Corrected input\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[1])\n",
    "    plt.imshow(MstM)\n",
    "    plt.title(\"Corrected visualization\")\n",
    "    remove_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(nbpix,transform_type):\n",
    "    \"\"\"\n",
    "    Build the set of one pixel matrices and apply the transformations\n",
    "    \"\"\"\n",
    "    # List of indexes where to put a black pixel\n",
    "    idx = range(0,nbpix**2,1)\n",
    "\n",
    "    # Initialize empty arrays \n",
    "    Mreal_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mmang_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mstar_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    for ii in idx:\n",
    "        # Fill the indexed pixel with a one\n",
    "        Mreal_tab[ii,ii] = 1\n",
    "        # Use the transformation matrices to generate Mmang and Mstar\n",
    "#         Mmang_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@P).reshape(1,nbpix**2)\n",
    "#         Mstar_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@Pstar).reshape(1,nbpix**2)\n",
    "            \n",
    "        if transform_type is \"translation\":    \n",
    "            Mmang_tab[ii,:] = translate2left(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = translate2right(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "        elif transform_type is \"rotation\":\n",
    "            Mmang_tab[ii,:] = rot90ccw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = rot90cw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            \n",
    "    return (Mreal_tab, Mmang_tab, Mstar_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add one on the designated index\n",
    "def add_one(arr,index):\n",
    "    arr[0,index] = 1\n",
    "    return arr\n",
    "\n",
    "# Function to split the matrix into matrices of one pixel\n",
    "def split_matrix(mat):\n",
    "    \"\"\" Split a matrix into matrices of one pixel\"\"\"\n",
    "    # find the indexes of the ones values in the matrix\n",
    "#     idx_arr = np.where(mat.reshape(1,nbpix**2)[0]==1)[0]\n",
    "    idx_arr = np.where(mat.reshape(1,nbpix**2)[0]>0)[0]\n",
    "    # transform from an array to a list\n",
    "    idx_lst = [idx_arr.item(ii) for ii in range(0,len(idx_arr))] \n",
    "    temp = np.zeros((1,nbpix**2))\n",
    "    mat_split = np.zeros((len(idx_lst), nbpix**2))\n",
    "#     Mtest = np.zeros((nbpix,nbpix))\n",
    "    for ii in range(0,len(idx_lst)):\n",
    "        mat_split[ii,idx_lst[ii]] = 1    \n",
    "#         Mtest = Mtest + Mreal_split[ii,:].reshape(nbpix,nbpix)\n",
    "    return mat_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction functions\n",
    "def perform_prediction(mat, model):\n",
    "    \"\"\" Predict the output with a trained model\"\"\"\n",
    "    # split the input matrix into matrices of one pixel\n",
    "    mat_split = split_matrix(mat)\n",
    "    nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "    # initializations\n",
    "    res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "    Mres = np.zeros((nbpix,nbpix))\n",
    "    # Loop on all the one pixels array\n",
    "    for ii in range(0,nb_dark_pxl):\n",
    "        # Apply the models to the one pixel matrices\n",
    "        print(mat_split[ii])\n",
    "        res[ii,:] = model.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "        # Sum up the results to construct the matrices\n",
    "        Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "    return Mres\n",
    "\n",
    "# def predict_corrector(mat):\n",
    "#     # split the input matrix into matrices of one pixel\n",
    "#     mat_split = split_matrix(mat)\n",
    "#     nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "#     # initializations\n",
    "#     res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "#     Mres = np.zeros((nbpix,nbpix))\n",
    "#     # Loop on all the one pixels array\n",
    "#     for ii in range(0,nb_dark_pxl):\n",
    "#         # Apply the models to the one pixel matrices\n",
    "#         res[ii,:] = model_corrector.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "#         # Sum up the results to construct the matrices\n",
    "#         Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "#     return Mres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_door_img(nbpix):\n",
    "    \"\"\" Create an nbpix by nbpix image of a door\"\"\"\n",
    "    nbborder = int(np.round(nbpix*0.3))\n",
    "    u = np.ones((nbborder,nbpix))\n",
    "    l = np.ones((nbpix-nbborder,nbborder))\n",
    "    r = l\n",
    "    door = np.zeros((nbpix-nbborder, nbpix-2*nbborder))\n",
    "\n",
    "    return np.concatenate((u,np.concatenate((l,door,r), axis=1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def grayscale_cmap(cmap):\n",
    "#     \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "#     cmap = plt.cm.get_cmap(cmap)\n",
    "#     colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "#     # convert RGBA to perceived grayscale luminance\n",
    "#     # cf. http://alienryderflex.com/hsp.html\n",
    "#     RGB_weight = [0.299, 0.587, 0.114]\n",
    "#     luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "#     colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "#     return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)\n",
    "\n",
    "# mpl.rc('image', cmap=grayscale_cmap(\"viridis_r\"))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nbpix = 4 # nb of pixel to consider (nbpix x nbpix)\n",
    "transform_type = \"rotation\" # type of transformation : \"translation\" or \"rotation\"\n",
    "training_type = \"full\" # type of training: \"partial\" of \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformation matrices\n",
    "\n",
    "# import random\n",
    "# (P,Pstar) = create_PPstar(nbpix)\n",
    "\n",
    "# Create the training data\n",
    "(Mreal_tab, Mmang_tab, Mstar_tab) = create_training_data(nbpix,transform_type)\n",
    "\n",
    "\n",
    "# the training input are the matrices of the real images with one pixel\n",
    "\n",
    "if training_type is \"partial\": # we remove randomly 20% of the training data\n",
    "    # rebuild the list of indexes and shuffle it\n",
    "    rdm_idx = list(range(0,nbpix**2,1))\n",
    "    random.shuffle(rdm_idx)\n",
    "    \n",
    "    # remove 80% of the indexes of this list\n",
    "    rdm_idx[0:int(np.round(nbpix**2*0.8))] = []\n",
    "    \n",
    "    # delete the corresponding rows in the training matrices\n",
    "    Mreal_tab = np.delete(Mreal_tab, rdm_idx, axis=0)\n",
    "    Mmang_tab = np.delete(Mmang_tab, rdm_idx, axis=0)\n",
    "    Mstar_tab = np.delete(Mstar_tab, rdm_idx, axis=0)\n",
    "    \n",
    "    print(f\"Training performed on {Mreal_tab.shape[0]}/{Mreal_tab.shape[1]} pixels\")\n",
    "\n",
    "idx = range(0,Mreal_tab.shape[0],1)        \n",
    "X_train = Mreal_tab   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/180\n",
      "36/36 [==============================] - 0s 8ms/step - loss: 3.5877 - acc: 0.0278\n",
      "Epoch 2/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5535 - acc: 0.1111\n",
      "Epoch 3/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.5275 - acc: 0.2222\n",
      "Epoch 4/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.5056 - acc: 0.2222\n",
      "Epoch 5/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4837 - acc: 0.3333\n",
      "Epoch 6/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4619 - acc: 0.3889\n",
      "Epoch 7/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.4405 - acc: 0.5833\n",
      "Epoch 8/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4190 - acc: 0.6389\n",
      "Epoch 9/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3973 - acc: 0.6667\n",
      "Epoch 10/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.3758 - acc: 0.7500\n",
      "Epoch 11/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.3529 - acc: 0.7778\n",
      "Epoch 12/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.3299 - acc: 0.8333\n",
      "Epoch 13/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3047 - acc: 0.8889\n",
      "Epoch 14/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.2803 - acc: 0.9167\n",
      "Epoch 15/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.2555 - acc: 0.9167\n",
      "Epoch 16/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.2298 - acc: 0.9167\n",
      "Epoch 17/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 3.2023 - acc: 0.9167\n",
      "Epoch 18/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1738 - acc: 0.9444\n",
      "Epoch 19/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1443 - acc: 0.9722\n",
      "Epoch 20/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1136 - acc: 0.9722\n",
      "Epoch 21/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.0811 - acc: 0.9722\n",
      "Epoch 22/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 3.0477 - acc: 1.0000\n",
      "Epoch 23/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.0124 - acc: 1.0000\n",
      "Epoch 24/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9769 - acc: 1.0000\n",
      "Epoch 25/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9401 - acc: 1.0000\n",
      "Epoch 26/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.9015 - acc: 1.0000\n",
      "Epoch 27/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.8615 - acc: 1.0000\n",
      "Epoch 28/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.8183 - acc: 1.0000\n",
      "Epoch 29/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.7715 - acc: 1.0000\n",
      "Epoch 30/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.7267 - acc: 1.0000\n",
      "Epoch 31/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.6773 - acc: 1.0000\n",
      "Epoch 32/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.6276 - acc: 1.0000\n",
      "Epoch 33/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.5761 - acc: 1.0000\n",
      "Epoch 34/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 2.5237 - acc: 1.0000\n",
      "Epoch 35/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.4711 - acc: 1.0000\n",
      "Epoch 36/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.4130 - acc: 1.0000\n",
      "Epoch 37/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.3562 - acc: 1.0000\n",
      "Epoch 38/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 2.2967 - acc: 1.0000\n",
      "Epoch 39/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.2336 - acc: 1.0000\n",
      "Epoch 40/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.1708 - acc: 1.0000\n",
      "Epoch 41/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.1050 - acc: 1.0000\n",
      "Epoch 42/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.0392 - acc: 1.0000\n",
      "Epoch 43/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.9592 - acc: 1.000 - 0s 417us/step - loss: 1.9707 - acc: 1.0000\n",
      "Epoch 44/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 1.9028 - acc: 1.0000\n",
      "Epoch 45/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.8340 - acc: 1.0000\n",
      "Epoch 46/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.7624 - acc: 1.0000\n",
      "Epoch 47/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.6933 - acc: 1.0000\n",
      "Epoch 48/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 1.6219 - acc: 1.0000\n",
      "Epoch 49/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.5512 - acc: 1.0000\n",
      "Epoch 50/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.4787 - acc: 1.0000\n",
      "Epoch 51/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.4061 - acc: 1.0000\n",
      "Epoch 52/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.3347 - acc: 1.0000\n",
      "Epoch 53/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.2669 - acc: 1.0000\n",
      "Epoch 54/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.1962 - acc: 1.0000\n",
      "Epoch 55/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 1.1316 - acc: 1.0000\n",
      "Epoch 56/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.0672 - acc: 1.0000\n",
      "Epoch 57/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.0010 - acc: 1.0000\n",
      "Epoch 58/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.9394 - acc: 1.0000\n",
      "Epoch 59/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.8800 - acc: 1.0000\n",
      "Epoch 60/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.8210 - acc: 1.0000\n",
      "Epoch 61/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.7642 - acc: 1.0000\n",
      "Epoch 62/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.7107 - acc: 1.0000\n",
      "Epoch 63/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.6609 - acc: 1.0000\n",
      "Epoch 64/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.6119 - acc: 1.0000\n",
      "Epoch 65/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.5676 - acc: 1.0000\n",
      "Epoch 66/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.5252 - acc: 1.0000\n",
      "Epoch 67/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.4860 - acc: 1.0000\n",
      "Epoch 68/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4507 - acc: 1.0000\n",
      "Epoch 69/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.4166 - acc: 1.0000\n",
      "Epoch 70/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.3857 - acc: 1.0000\n",
      "Epoch 71/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3570 - acc: 1.0000\n",
      "Epoch 72/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.3317 - acc: 1.0000\n",
      "Epoch 73/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3078 - acc: 1.0000\n",
      "Epoch 74/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2870 - acc: 1.0000\n",
      "Epoch 75/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.2672 - acc: 1.0000\n",
      "Epoch 76/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.2490 - acc: 1.0000\n",
      "Epoch 77/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2330 - acc: 1.0000\n",
      "Epoch 78/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2178 - acc: 1.0000\n",
      "Epoch 79/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.2039 - acc: 1.0000\n",
      "Epoch 80/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1906 - acc: 1.0000\n",
      "Epoch 81/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.1789 - acc: 1.0000\n",
      "Epoch 82/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1676 - acc: 1.0000\n",
      "Epoch 83/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1575 - acc: 1.0000\n",
      "Epoch 84/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1484 - acc: 1.0000\n",
      "Epoch 85/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 194us/step - loss: 0.1397 - acc: 1.0000\n",
      "Epoch 86/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.1320 - acc: 1.0000\n",
      "Epoch 87/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.1250 - acc: 1.0000\n",
      "Epoch 88/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.1188 - acc: 1.0000\n",
      "Epoch 89/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1131 - acc: 1.0000\n",
      "Epoch 90/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1078 - acc: 1.0000\n",
      "Epoch 91/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.1029 - acc: 1.0000\n",
      "Epoch 92/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0981 - acc: 1.0000\n",
      "Epoch 93/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0937 - acc: 1.0000\n",
      "Epoch 94/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0893 - acc: 1.0000\n",
      "Epoch 95/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0856 - acc: 1.0000\n",
      "Epoch 96/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0821 - acc: 1.0000\n",
      "Epoch 97/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0788 - acc: 1.0000\n",
      "Epoch 98/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0758 - acc: 1.0000\n",
      "Epoch 99/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0730 - acc: 1.0000\n",
      "Epoch 100/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0704 - acc: 1.0000\n",
      "Epoch 101/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0679 - acc: 1.0000\n",
      "Epoch 102/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0655 - acc: 1.0000\n",
      "Epoch 103/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0632 - acc: 1.0000\n",
      "Epoch 104/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0610 - acc: 1.0000\n",
      "Epoch 105/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0591 - acc: 1.0000\n",
      "Epoch 106/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0573 - acc: 1.0000\n",
      "Epoch 107/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0555 - acc: 1.0000\n",
      "Epoch 108/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0538 - acc: 1.0000\n",
      "Epoch 109/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0521 - acc: 1.0000\n",
      "Epoch 110/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0505 - acc: 1.0000\n",
      "Epoch 111/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0489 - acc: 1.0000\n",
      "Epoch 112/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0476 - acc: 1.0000\n",
      "Epoch 113/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 114/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0451 - acc: 1.0000\n",
      "Epoch 115/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0439 - acc: 1.0000\n",
      "Epoch 116/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0428 - acc: 1.0000\n",
      "Epoch 117/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0417 - acc: 1.0000\n",
      "Epoch 118/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0407 - acc: 1.0000\n",
      "Epoch 119/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0397 - acc: 1.0000\n",
      "Epoch 120/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0388 - acc: 1.0000\n",
      "Epoch 121/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0379 - acc: 1.0000\n",
      "Epoch 122/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0371 - acc: 1.0000\n",
      "Epoch 123/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0362 - acc: 1.0000\n",
      "Epoch 124/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 125/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0347 - acc: 1.0000\n",
      "Epoch 126/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0339 - acc: 1.0000\n",
      "Epoch 127/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0331 - acc: 1.0000\n",
      "Epoch 128/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0324 - acc: 1.0000\n",
      "Epoch 129/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0317 - acc: 1.0000\n",
      "Epoch 130/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0310 - acc: 1.0000\n",
      "Epoch 131/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0303 - acc: 1.0000\n",
      "Epoch 132/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0296 - acc: 1.0000\n",
      "Epoch 133/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0290 - acc: 1.0000\n",
      "Epoch 134/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0284 - acc: 1.0000\n",
      "Epoch 135/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0278 - acc: 1.0000\n",
      "Epoch 136/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0273 - acc: 1.0000\n",
      "Epoch 137/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0267 - acc: 1.0000\n",
      "Epoch 138/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0262 - acc: 1.0000\n",
      "Epoch 139/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 140/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0253 - acc: 1.0000\n",
      "Epoch 141/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0249 - acc: 1.0000\n",
      "Epoch 142/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 143/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 144/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 145/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 146/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 147/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0225 - acc: 1.0000\n",
      "Epoch 148/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0221 - acc: 1.0000\n",
      "Epoch 149/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0218 - acc: 1.0000\n",
      "Epoch 150/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 151/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0211 - acc: 1.000 - 0s 167us/step - loss: 0.0211 - acc: 1.0000\n",
      "Epoch 152/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0207 - acc: 1.0000\n",
      "Epoch 153/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0204 - acc: 1.0000\n",
      "Epoch 154/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0201 - acc: 1.0000\n",
      "Epoch 155/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 156/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0194 - acc: 1.0000\n",
      "Epoch 157/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0191 - acc: 1.0000\n",
      "Epoch 158/180\n",
      "36/36 [==============================] - 0s 694us/step - loss: 0.0188 - acc: 1.0000\n",
      "Epoch 159/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0185 - acc: 1.0000\n",
      "Epoch 160/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 161/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 162/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 163/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 164/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 165/180\n",
      "36/36 [==============================] - 0s 111us/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 166/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0167 - acc: 1.0000\n",
      "Epoch 167/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 168/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 222us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 169/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0160 - acc: 1.0000\n",
      "Epoch 170/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 171/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 172/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 173/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 174/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 175/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 176/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 177/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 178/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 179/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 180/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0137 - acc: 1.0000\n",
      "Epoch 1/180\n",
      "36/36 [==============================] - 0s 7ms/step - loss: 3.5878 - acc: 0.0000e+00\n",
      "Epoch 2/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5538 - acc: 0.0278\n",
      "Epoch 3/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5294 - acc: 0.0833\n",
      "Epoch 4/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.5072 - acc: 0.2500\n",
      "Epoch 5/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.4858 - acc: 0.3611\n",
      "Epoch 6/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4646 - acc: 0.5000\n",
      "Epoch 7/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.4456 - acc: 0.5000\n",
      "Epoch 8/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.4255 - acc: 0.5833\n",
      "Epoch 9/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.4042 - acc: 0.6111\n",
      "Epoch 10/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.3834 - acc: 0.7222\n",
      "Epoch 11/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.3622 - acc: 0.8889\n",
      "Epoch 12/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.3397 - acc: 0.9444\n",
      "Epoch 13/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.3165 - acc: 0.9444\n",
      "Epoch 14/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.2924 - acc: 0.9722\n",
      "Epoch 15/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 3.2681 - acc: 1.0000\n",
      "Epoch 16/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 3.2432 - acc: 1.0000\n",
      "Epoch 17/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.2167 - acc: 1.0000\n",
      "Epoch 18/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1904 - acc: 1.0000\n",
      "Epoch 19/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.1617 - acc: 1.0000\n",
      "Epoch 20/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 3.1317 - acc: 1.0000\n",
      "Epoch 21/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 3.0997 - acc: 1.0000\n",
      "Epoch 22/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 3.0687 - acc: 1.0000\n",
      "Epoch 23/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 3.0359 - acc: 1.0000\n",
      "Epoch 24/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 3.0004 - acc: 1.0000\n",
      "Epoch 25/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.9651 - acc: 1.0000\n",
      "Epoch 26/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.9262 - acc: 1.0000\n",
      "Epoch 27/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.8868 - acc: 1.0000\n",
      "Epoch 28/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.8453 - acc: 1.0000\n",
      "Epoch 29/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.8012 - acc: 1.0000\n",
      "Epoch 30/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.7561 - acc: 1.0000\n",
      "Epoch 31/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.7095 - acc: 1.0000\n",
      "Epoch 32/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.6622 - acc: 1.0000\n",
      "Epoch 33/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.6125 - acc: 1.0000\n",
      "Epoch 34/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.5606 - acc: 1.0000\n",
      "Epoch 35/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.5070 - acc: 1.0000\n",
      "Epoch 36/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 2.4534 - acc: 1.0000\n",
      "Epoch 37/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.3973 - acc: 1.0000\n",
      "Epoch 38/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 2.3384 - acc: 1.0000\n",
      "Epoch 39/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 2.2798 - acc: 1.0000\n",
      "Epoch 40/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 2.2191 - acc: 1.0000\n",
      "Epoch 41/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 2.1598 - acc: 1.0000\n",
      "Epoch 42/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 2.0981 - acc: 1.0000\n",
      "Epoch 43/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 2.0327 - acc: 1.0000\n",
      "Epoch 44/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.9666 - acc: 1.0000\n",
      "Epoch 45/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.8976 - acc: 1.0000\n",
      "Epoch 46/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.8299 - acc: 1.0000\n",
      "Epoch 47/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 1.7617 - acc: 1.0000\n",
      "Epoch 48/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.6935 - acc: 1.0000\n",
      "Epoch 49/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.6249 - acc: 1.0000\n",
      "Epoch 50/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.5562 - acc: 1.0000\n",
      "Epoch 51/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.4877 - acc: 1.0000\n",
      "Epoch 52/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.4193 - acc: 1.0000\n",
      "Epoch 53/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 1.3477 - acc: 1.0000\n",
      "Epoch 54/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.2798 - acc: 1.0000\n",
      "Epoch 55/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 1.2090 - acc: 1.0000\n",
      "Epoch 56/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 1.1416 - acc: 1.0000\n",
      "Epoch 57/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 1.0753 - acc: 1.0000\n",
      "Epoch 58/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 1.0069 - acc: 1.000 - 0s 222us/step - loss: 1.0122 - acc: 1.0000\n",
      "Epoch 59/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.9491 - acc: 1.0000\n",
      "Epoch 60/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.8873 - acc: 1.0000\n",
      "Epoch 61/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.8308 - acc: 1.0000\n",
      "Epoch 62/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.7738 - acc: 1.0000\n",
      "Epoch 63/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.7172 - acc: 1.0000\n",
      "Epoch 64/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.6664 - acc: 1.0000\n",
      "Epoch 65/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.6181 - acc: 1.0000\n",
      "Epoch 66/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.5755 - acc: 1.0000\n",
      "Epoch 67/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.5348 - acc: 1.0000\n",
      "Epoch 68/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4963 - acc: 1.0000\n",
      "Epoch 69/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.4590 - acc: 1.0000\n",
      "Epoch 70/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.4248 - acc: 1.0000\n",
      "Epoch 71/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.3929 - acc: 1.0000\n",
      "Epoch 72/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 167us/step - loss: 0.3622 - acc: 1.0000\n",
      "Epoch 73/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.3328 - acc: 1.0000\n",
      "Epoch 74/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.3072 - acc: 1.0000\n",
      "Epoch 75/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.2833 - acc: 1.0000\n",
      "Epoch 76/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.2607 - acc: 1.0000\n",
      "Epoch 77/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.2420 - acc: 1.0000\n",
      "Epoch 78/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.2245 - acc: 1.0000\n",
      "Epoch 79/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.2098 - acc: 1.0000\n",
      "Epoch 80/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1956 - acc: 1.0000\n",
      "Epoch 81/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.1827 - acc: 1.0000\n",
      "Epoch 82/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1709 - acc: 1.0000\n",
      "Epoch 83/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1597 - acc: 1.0000\n",
      "Epoch 84/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1498 - acc: 1.0000\n",
      "Epoch 85/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1411 - acc: 1.0000\n",
      "Epoch 86/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.1335 - acc: 1.0000\n",
      "Epoch 87/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1265 - acc: 1.0000\n",
      "Epoch 88/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1201 - acc: 1.0000\n",
      "Epoch 89/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.1142 - acc: 1.0000\n",
      "Epoch 90/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.1092 - acc: 1.0000\n",
      "Epoch 91/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.1043 - acc: 1.0000\n",
      "Epoch 92/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0999 - acc: 1.0000\n",
      "Epoch 93/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0957 - acc: 1.0000\n",
      "Epoch 94/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0916 - acc: 1.0000\n",
      "Epoch 95/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0878 - acc: 1.0000\n",
      "Epoch 96/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0841 - acc: 1.0000\n",
      "Epoch 97/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0806 - acc: 1.0000\n",
      "Epoch 98/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0775 - acc: 1.0000\n",
      "Epoch 99/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0746 - acc: 1.0000\n",
      "Epoch 100/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0719 - acc: 1.0000\n",
      "Epoch 101/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.0694 - acc: 1.0000\n",
      "Epoch 102/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0668 - acc: 1.0000\n",
      "Epoch 103/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0645 - acc: 1.0000\n",
      "Epoch 104/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0620 - acc: 1.0000\n",
      "Epoch 105/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0600 - acc: 1.0000\n",
      "Epoch 106/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0581 - acc: 1.0000\n",
      "Epoch 107/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0562 - acc: 1.0000\n",
      "Epoch 108/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0544 - acc: 1.0000\n",
      "Epoch 109/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0527 - acc: 1.0000\n",
      "Epoch 110/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0511 - acc: 1.0000\n",
      "Epoch 111/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0497 - acc: 1.0000\n",
      "Epoch 112/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0482 - acc: 1.0000\n",
      "Epoch 113/180\n",
      "36/36 [==============================] - 0s 444us/step - loss: 0.0469 - acc: 1.0000\n",
      "Epoch 114/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0456 - acc: 1.0000\n",
      "Epoch 115/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0444 - acc: 1.0000\n",
      "Epoch 116/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0432 - acc: 1.0000\n",
      "Epoch 117/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0421 - acc: 1.0000\n",
      "Epoch 118/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0411 - acc: 1.0000\n",
      "Epoch 119/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0400 - acc: 1.0000\n",
      "Epoch 120/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0391 - acc: 1.0000\n",
      "Epoch 121/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0381 - acc: 1.0000\n",
      "Epoch 122/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0372 - acc: 1.0000\n",
      "Epoch 123/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0364 - acc: 1.0000\n",
      "Epoch 124/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0356 - acc: 1.0000\n",
      "Epoch 125/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0348 - acc: 1.0000\n",
      "Epoch 126/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0340 - acc: 1.0000\n",
      "Epoch 127/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0332 - acc: 1.0000\n",
      "Epoch 128/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 129/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0318 - acc: 1.0000\n",
      "Epoch 130/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0311 - acc: 1.0000\n",
      "Epoch 131/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0304 - acc: 1.0000\n",
      "Epoch 132/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0298 - acc: 1.0000\n",
      "Epoch 133/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0292 - acc: 1.0000\n",
      "Epoch 134/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0286 - acc: 1.0000\n",
      "Epoch 135/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0280 - acc: 1.0000\n",
      "Epoch 136/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0274 - acc: 1.0000\n",
      "Epoch 137/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0269 - acc: 1.0000\n",
      "Epoch 138/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0264 - acc: 1.0000\n",
      "Epoch 139/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0259 - acc: 1.0000\n",
      "Epoch 140/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0255 - acc: 1.0000\n",
      "Epoch 141/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0250 - acc: 1.0000\n",
      "Epoch 142/180\n",
      "36/36 [==============================] - 0s 278us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 143/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0241 - acc: 1.0000\n",
      "Epoch 144/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0236 - acc: 1.0000\n",
      "Epoch 145/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0232 - acc: 1.0000\n",
      "Epoch 146/180\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.0229 - acc: 1.000 - 0s 194us/step - loss: 0.0228 - acc: 1.0000\n",
      "Epoch 147/180\n",
      "36/36 [==============================] - 0s 167us/step - loss: 0.0224 - acc: 1.0000\n",
      "Epoch 148/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0220 - acc: 1.0000\n",
      "Epoch 149/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 150/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0213 - acc: 1.0000\n",
      "Epoch 151/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0209 - acc: 1.0000\n",
      "Epoch 152/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0206 - acc: 1.0000\n",
      "Epoch 153/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0202 - acc: 1.0000\n",
      "Epoch 154/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0199 - acc: 1.0000\n",
      "Epoch 155/180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 167us/step - loss: 0.0196 - acc: 1.0000\n",
      "Epoch 156/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 157/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 158/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0187 - acc: 1.0000\n",
      "Epoch 159/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 160/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0182 - acc: 1.0000\n",
      "Epoch 161/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0179 - acc: 1.0000\n",
      "Epoch 162/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0176 - acc: 1.0000\n",
      "Epoch 163/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 164/180\n",
      "36/36 [==============================] - 0s 139us/step - loss: 0.0171 - acc: 1.0000\n",
      "Epoch 165/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 166/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 167/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0164 - acc: 1.0000\n",
      "Epoch 168/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0162 - acc: 1.0000\n",
      "Epoch 169/180\n",
      "36/36 [==============================] - 0s 528us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 170/180\n",
      "36/36 [==============================] - 0s 361us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 171/180\n",
      "36/36 [==============================] - 0s 389us/step - loss: 0.0155 - acc: 1.0000\n",
      "Epoch 172/180\n",
      "36/36 [==============================] - 0s 306us/step - loss: 0.0153 - acc: 1.0000\n",
      "Epoch 173/180\n",
      "36/36 [==============================] - 0s 444us/step - loss: 0.0151 - acc: 1.0000\n",
      "Epoch 174/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0149 - acc: 1.0000\n",
      "Epoch 175/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0147 - acc: 1.0000\n",
      "Epoch 176/180\n",
      "36/36 [==============================] - 0s 417us/step - loss: 0.0145 - acc: 1.0000\n",
      "Epoch 177/180\n",
      "36/36 [==============================] - 0s 333us/step - loss: 0.0143 - acc: 1.0000\n",
      "Epoch 178/180\n",
      "36/36 [==============================] - 0s 250us/step - loss: 0.0141 - acc: 1.0000\n",
      "Epoch 179/180\n",
      "36/36 [==============================] - 0s 194us/step - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 180/180\n",
      "36/36 [==============================] - 0s 222us/step - loss: 0.0137 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# the training output will be the category corresponding to the position of the pixel in the mangled image\n",
    "y_train = [np.where(Mmang_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train = to_categorical(y_train, nbpix**2)\n",
    "\n",
    "# or the position of the pixel in the corrected image\n",
    "y_train_cor = [np.where(Mstar_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train_cor = to_categorical(y_train_cor, nbpix**2)\n",
    "\n",
    "# creating the models\n",
    "model_mangler = Sequential()\n",
    "model_mangler.add(Dense(4*nbpix**2, activation='relu', input_dim=nbpix**2))\n",
    "model_mangler.add(Dense(4*nbpix**2, activation='relu'))\n",
    "model_mangler.add(Dense(nbpix**2, activation='softmax'))\n",
    "# Inversion strategy doesnt work very well...\n",
    "# we are going to try using another model, trained on the corrected input.\n",
    "model_corrector = Sequential()\n",
    "model_corrector.add(Dense(4*nbpix**2, activation='relu', input_dim=nbpix**2))\n",
    "model_corrector.add(Dense(4*nbpix**2, activation='relu'))\n",
    "model_corrector.add(Dense(nbpix**2, activation='softmax'))\n",
    "\n",
    "# Compile the models\n",
    "model_mangler.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_corrector.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# train the model \"mangler\"\n",
    "model_mangler.fit( X_train,\n",
    "    y_train,\n",
    "    epochs=5*nbpix**2,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# train the corrected input model\n",
    "model_corrector.fit( X_train,\n",
    "    y_train_cor,\n",
    "    epochs=5*nbpix**2,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")    \n",
    "\n",
    "# model_mangler.summary()\n",
    "# model_corrector.summary()\n",
    "\n",
    "# Save the models\n",
    "model_mangler.save(f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "model_corrector.save(f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the models to an existing image\n",
    "\n",
    "# Load the saved models\n",
    "model_mangler = load_model(f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "model_corrector = load_model(f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mreal = create_door_img(nbpix) \n",
    "cut = 0.5\n",
    "Mreal = np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut])\n",
    "# Mreal_split = split_matrix(Mreal)\n",
    "\n",
    "# Predict the mangled image based on the real one\n",
    "Mmang_ml = perform_prediction(Mreal,model_mangler ) # predict_mangler(Mreal)\n",
    "# Predict the corrected input based on the real image\n",
    "Mcor_ml = perform_prediction(Mreal, model_corrector)# predict_corrector(Mreal)\n",
    "# Prediction of the output from the corrected input\n",
    "Mout_ml = perform_prediction(np.round(Mcor_ml), model_mangler)\n",
    "# plot the results\n",
    "# vis_matrices(Mreal, Mmang_ml,Mcor_ml, Mout_ml)\n",
    "if transform_type is \"translation\":\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, translate2left(Mcor_ml))\n",
    "elif transform_type is \"rotation\":\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, rot90ccw(Mcor_ml))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vis_matrices(Mreal, rot90ccw(Mreal),rot90cw(Mreal), rot90ccw(rot90cw(Mreal)))\n",
    "\n",
    "from flask import jsonify\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import codecs, json \n",
    "\n",
    "a = np.arange(10).reshape(2,5) # a 2 by 5 array\n",
    "b = a.tolist() # nested lists with same data, indices\n",
    "file_path = \"/path.json\" ## your path variable\n",
    "json.dump(b, codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4) ### this saves the array in .json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "{\"mat\": [[0, 0, 0, 1], [0, 0, 1, 1], [1, 1, 0, 0], [0, 0, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(a.shape)\n",
    "\n",
    "# json_dump = json.dumps({'a': a, 'aa': [2, (2, 3, 4), a], 'bb': [2]}, cls=NumpyEncoder)\n",
    "json_dump = json.dumps({\"mat\": Mreal}, cls=NumpyEncoder)\n",
    "print(json_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[[0 0 0 0]\n",
      " [1 0 0 0]\n",
      " [1 1 1 0]\n",
      " [1 1 1 0]]\n",
      "{\"a\": [[1, 0, 0, 1], [0, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 1]]}\n"
     ]
    }
   ],
   "source": [
    "cut = 0.5\n",
    "print(nbpix)\n",
    "rmd_img = np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut])\n",
    "print(np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut]))\n",
    "json_dump = json.dumps({\"a\": rmd_img} , cls=NumpyEncoder)\n",
    "print(json_dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\"{\\\\\"a\\\\\": [[1, 0, 0, 1], [0, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 1]]}\"]'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.Series(json_dump).to_json(orient='values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayToList(arr):\n",
    "    return [ii.item() for ii in arr.reshape((arr.size,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform into a list\n",
    "mat_list = [ii.item() for ii in Mreal.reshape((nbpix**2,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 1]\n",
      " [0 0 1 1]\n",
      " [1 1 0 0]\n",
      " [0 0 1 1]]\n",
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayToList(Mreal)\n",
    "# Mreal.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4,16,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8, 10, 12, 14]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayToList(np.arange(4,16,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
