{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle different types of transformation\n",
    "# different nb of pixels\n",
    "# different nb of level of gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MariO\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "# from sklearn import tree\n",
    "import os\n",
    "import random\n",
    "\n",
    "mpl.rc('image', cmap='gray_r')\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rot90ccw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg counter clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, 1],\n",
    "               [-1,0]])\n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][0] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot\n",
    "\n",
    "def rot90cw(mat):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg clock wise\"\"\"\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, -1],\n",
    "               [1,0]])    \n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    for ii in range(0,len(coord)):\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][1] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation matrices\n",
    "def create_PPstar_translation(nbpix):\n",
    "    # nb of pixels translated\n",
    "    nbt = int(np.round(0.25*nbpix))\n",
    "\n",
    "    # bottom left square block\n",
    "    bl = np.eye(nbpix-nbt,nbpix-nbt)\n",
    "    # upper right square block\n",
    "    ur = np.eye(nbt,nbt)\n",
    "    # upper left rect block\n",
    "    ul = np.zeros((nbt,nbpix-nbt))\n",
    "    # bottom right rect block\n",
    "    br = np.zeros((nbpix-nbt,nbt))\n",
    "\n",
    "    # concatenate the blocks to build the transformation matrix\n",
    "    P = np.concatenate((np.concatenate((ul,ur), axis=1), np.concatenate((bl,br), axis=1)), axis=0)\n",
    "    Pstar = np.linalg.inv(P)        \n",
    "    return (P,Pstar)\n",
    "\n",
    "def translate2left(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@P\n",
    "def translate2right(mat):\n",
    "    P,Pstar = create_PPstar_translation(mat.shape[0])\n",
    "    return mat@Pstar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(1)\n",
    "def remove_ticks():\n",
    "    plt.tick_params(\n",
    "    axis='x',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    labelbottom=False) # labels along the bottom edge are off\n",
    "    plt.tick_params(\n",
    "    axis='y',          # changes apply to the x-axis\n",
    "    which='both',      # both major and minor ticks are affected\n",
    "    bottom=False,      # ticks along the bottom edge are off\n",
    "    top=False,         # ticks along the top edge are off\n",
    "    left=False,\n",
    "    labelleft=False,\n",
    "    labelbottom=False) # labels along the bottom edge are off    \n",
    "    return\n",
    "\n",
    "def vis_matrices(Mr, Mm, Mst, MstM):\n",
    "#     print(Mr.shape[0])\n",
    "    if Mr.shape[0]==1:\n",
    "        Mr = Mr.reshape(int(np.sqrt(Mr.shape[1])), int(np.sqrt(Mr.shape[1])))\n",
    "        Mm = Mm.reshape(int(np.sqrt(Mm.shape[1])), int(np.sqrt(Mm.shape[1])))\n",
    "        Mst = Mst.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "        MstM = MstM.reshape(int(np.sqrt(Mst.shape[1])), int(np.sqrt(Mst.shape[1])))\n",
    "\n",
    "    \n",
    "    fig, (ax1,ax2) = plt.subplots(nrows=2,ncols=2) #, squeeze=True, sharey=True)\n",
    "    fig.set_size_inches(8,8)\n",
    "\n",
    "    plt.sca(ax1[0])\n",
    "    plt.imshow(Mr)\n",
    "    plt.title(\"Real image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[0])\n",
    "    plt.imshow(Mm)\n",
    "    plt.title(\"Distorted image\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax1[1])\n",
    "    plt.imshow(Mst)\n",
    "    plt.title(\"Corrected input\")\n",
    "    remove_ticks()\n",
    "\n",
    "    plt.sca(ax2[1])\n",
    "    plt.imshow(MstM)\n",
    "    plt.title(\"Corrected visualization\")\n",
    "    remove_ticks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data(nbpix,transform_type):\n",
    "    \"\"\"\n",
    "    Build the set of one pixel matrices and apply the transformations\n",
    "    \"\"\"\n",
    "    # List of indexes where to put a black pixel\n",
    "    idx = range(0,nbpix**2,1)\n",
    "\n",
    "    # Initialize empty arrays \n",
    "    Mreal_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mmang_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    Mstar_tab = np.zeros((len(idx),nbpix*nbpix))\n",
    "    for ii in idx:\n",
    "        # Fill the indexed pixel with a one\n",
    "        Mreal_tab[ii,ii] = 1\n",
    "        # Use the transformation matrices to generate Mmang and Mstar\n",
    "#         Mmang_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@P).reshape(1,nbpix**2)\n",
    "#         Mstar_tab[ii,:] = (Mreal_tab[ii,:].reshape(nbpix,nbpix)@Pstar).reshape(1,nbpix**2)\n",
    "            \n",
    "        if transform_type is \"translation\":    \n",
    "            Mmang_tab[ii,:] = translate2left(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = translate2right(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "        elif transform_type is \"rotation\":\n",
    "            Mmang_tab[ii,:] = rot90ccw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            Mstar_tab[ii,:] = rot90cw(Mreal_tab[ii,:].reshape(nbpix,nbpix)).reshape(1,nbpix**2)\n",
    "            \n",
    "    return (Mreal_tab, Mmang_tab, Mstar_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add one on the designated index\n",
    "def add_one(arr,index):\n",
    "    arr[0,index] = 1\n",
    "    return arr\n",
    "\n",
    "# Function to split the matrix into matrices of one pixel\n",
    "def split_matrix(mat):\n",
    "    \"\"\" Split a matrix into matrices of one pixel\"\"\"\n",
    "    # find the indexes of the ones values in the matrix\n",
    "#     idx_arr = np.where(mat.reshape(1,nbpix**2)[0]==1)[0]\n",
    "    idx_arr = np.where(mat.reshape(1,nbpix**2)[0]>0)[0]\n",
    "    # transform from an array to a list\n",
    "    idx_lst = [idx_arr.item(ii) for ii in range(0,len(idx_arr))] \n",
    "    temp = np.zeros((1,nbpix**2))\n",
    "    mat_split = np.zeros((len(idx_lst), nbpix**2))\n",
    "#     Mtest = np.zeros((nbpix,nbpix))\n",
    "    for ii in range(0,len(idx_lst)):\n",
    "        mat_split[ii,idx_lst[ii]] = 1    \n",
    "#         Mtest = Mtest + Mreal_split[ii,:].reshape(nbpix,nbpix)\n",
    "    return mat_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction functions\n",
    "def perform_prediction(mat, model):\n",
    "    \"\"\" Predict the output with a trained model\"\"\"\n",
    "    # split the input matrix into matrices of one pixel\n",
    "    mat_split = split_matrix(mat)\n",
    "    nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "    # initializations\n",
    "    res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "    Mres = np.zeros((nbpix,nbpix))\n",
    "    # Loop on all the one pixels array\n",
    "    for ii in range(0,nb_dark_pxl):\n",
    "        # Apply the models to the one pixel matrices\n",
    "#         print(mat_split[ii])\n",
    "        res[ii,:] = model.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "        # Sum up the results to construct the matrices\n",
    "        Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "    return Mres\n",
    "\n",
    "# def predict_corrector(mat):\n",
    "#     # split the input matrix into matrices of one pixel\n",
    "#     mat_split = split_matrix(mat)\n",
    "#     nb_dark_pxl = mat_split.shape[0]\n",
    "    \n",
    "#     # initializations\n",
    "#     res = np.zeros((nb_dark_pxl, nbpix**2))\n",
    "#     Mres = np.zeros((nbpix,nbpix))\n",
    "#     # Loop on all the one pixels array\n",
    "#     for ii in range(0,nb_dark_pxl):\n",
    "#         # Apply the models to the one pixel matrices\n",
    "#         res[ii,:] = model_corrector.predict(np.expand_dims(mat_split[ii], axis=0))\n",
    "#         # Sum up the results to construct the matrices\n",
    "#         Mres = Mres + res[ii,:].reshape(nbpix,nbpix)\n",
    "#     return Mres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_door_img(nbpix):\n",
    "    \"\"\" Create an nbpix by nbpix image of a door\"\"\"\n",
    "    nbborder = int(np.round(nbpix*0.3))\n",
    "    u = np.ones((nbborder,nbpix))\n",
    "    l = np.ones((nbpix-nbborder,nbborder))\n",
    "    r = l\n",
    "    door = np.zeros((nbpix-nbborder, nbpix-2*nbborder))\n",
    "\n",
    "    return np.concatenate((u,np.concatenate((l,door,r), axis=1)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def grayscale_cmap(cmap):\n",
    "#     \"\"\"Return a grayscale version of the given colormap\"\"\"\n",
    "#     cmap = plt.cm.get_cmap(cmap)\n",
    "#     colors = cmap(np.arange(cmap.N))\n",
    "    \n",
    "#     # convert RGBA to perceived grayscale luminance\n",
    "#     # cf. http://alienryderflex.com/hsp.html\n",
    "#     RGB_weight = [0.299, 0.587, 0.114]\n",
    "#     luminance = np.sqrt(np.dot(colors[:, :3] ** 2, RGB_weight))\n",
    "#     colors[:, :3] = luminance[:, np.newaxis]\n",
    "        \n",
    "#     return LinearSegmentedColormap.from_list(cmap.name + \"_gray\", colors, cmap.N)\n",
    "\n",
    "# mpl.rc('image', cmap=grayscale_cmap(\"viridis_r\"))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "nbpix = 8 # nb of pixel to consider (nbpix x nbpix)\n",
    "transform_type = \"rotation\" # type of transformation : \"translation\" or \"rotation\"\n",
    "training_type = \"full\" # type of training: \"partial\" of \"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the transformation matrices\n",
    "\n",
    "# import random\n",
    "# (P,Pstar) = create_PPstar(nbpix)\n",
    "\n",
    "# Create the training data\n",
    "(Mreal_tab, Mmang_tab, Mstar_tab) = create_training_data(nbpix,transform_type)\n",
    "\n",
    "\n",
    "# the training input are the matrices of the real images with one pixel\n",
    "\n",
    "if training_type == \"partial\": # we remove randomly 20% of the training data\n",
    "    # rebuild the list of indexes and shuffle it\n",
    "    rdm_idx = list(range(0,nbpix**2,1))\n",
    "    random.shuffle(rdm_idx)\n",
    "    \n",
    "    # remove 80% of the indexes of this list\n",
    "    rdm_idx[0:int(np.round(nbpix**2*0.8))] = []\n",
    "    \n",
    "    # delete the corresponding rows in the training matrices\n",
    "    Mreal_tab = np.delete(Mreal_tab, rdm_idx, axis=0)\n",
    "    Mmang_tab = np.delete(Mmang_tab, rdm_idx, axis=0)\n",
    "    Mstar_tab = np.delete(Mstar_tab, rdm_idx, axis=0)\n",
    "    \n",
    "    print(f\"Training performed on {Mreal_tab.shape[0]}/{Mreal_tab.shape[1]} pixels\")\n",
    "\n",
    "idx = range(0,Mreal_tab.shape[0],1)        \n",
    "X_train = Mreal_tab   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "64/64 [==============================] - 1s 17ms/step - loss: 4.1604 - acc: 0.0312\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 4.1095 - acc: 0.2344\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 4.0667 - acc: 0.4375\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 4.0251 - acc: 0.5938\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 3.9815 - acc: 0.7969\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.9363 - acc: 0.9219\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 3.8878 - acc: 0.9531\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 3.8351 - acc: 0.9844\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.7790 - acc: 1.0000\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 3.7190 - acc: 1.0000\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 3.6539 - acc: 1.0000\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 3.5824 - acc: 1.0000\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.5063 - acc: 1.0000\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 3.4233 - acc: 1.0000\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 3.3345 - acc: 1.0000\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 3.2392 - acc: 1.0000\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 3.1363 - acc: 1.0000\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 3.0265 - acc: 1.0000\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 2.9081 - acc: 1.0000\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 2.7841 - acc: 1.0000\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 2.6517 - acc: 1.0000\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 2.5113 - acc: 1.0000\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 2.3640 - acc: 1.0000\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 2.2095 - acc: 1.0000\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 2.0486 - acc: 1.0000\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 1.8829 - acc: 1.0000\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.7138 - acc: 1.0000\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.5416 - acc: 1.0000\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 1.3698 - acc: 1.0000\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 1.2025 - acc: 1.0000\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 1.0386 - acc: 1.0000\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.8846 - acc: 1.0000\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.7436 - acc: 1.0000\n",
      "Epoch 34/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.6163 - acc: 1.0000\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.5048 - acc: 1.0000\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.4087 - acc: 1.0000\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3456 - acc: 1.000 - 0s 266us/step - loss: 0.3316 - acc: 1.0000\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.2675 - acc: 1.0000\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.2161 - acc: 1.0000\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.1765 - acc: 1.0000\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.1449 - acc: 1.0000\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.1202 - acc: 1.0000\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.1015 - acc: 1.0000\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0864 - acc: 1.0000\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0744 - acc: 1.0000\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0651 - acc: 1.0000\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0575 - acc: 1.0000\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0513 - acc: 1.0000\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0462 - acc: 1.0000\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0419 - acc: 1.0000\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0384 - acc: 1.0000\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0355 - acc: 1.0000\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0329 - acc: 1.0000\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0308 - acc: 1.0000\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0289 - acc: 1.0000\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0272 - acc: 1.0000\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0258 - acc: 1.0000\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0245 - acc: 1.0000\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0233 - acc: 1.0000\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0223 - acc: 1.0000\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0214 - acc: 1.0000\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0205 - acc: 1.0000\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0197 - acc: 1.0000\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0190 - acc: 1.0000\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0184 - acc: 1.0000\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0177 - acc: 1.0000\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0172 - acc: 1.0000\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0166 - acc: 1.0000\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0161 - acc: 1.0000\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0157 - acc: 1.0000\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0152 - acc: 1.0000\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0148 - acc: 1.0000\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0144 - acc: 1.0000\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0136 - acc: 1.0000\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0133 - acc: 1.0000\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0130 - acc: 1.0000\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0127 - acc: 1.0000\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0123 - acc: 1.0000\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0121 - acc: 1.0000\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0118 - acc: 1.0000\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0113 - acc: 1.0000\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0110 - acc: 1.0000\n",
      "Epoch 85/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 156us/step - loss: 0.0108 - acc: 1.0000\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0105 - acc: 1.0000\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0103 - acc: 1.0000\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0101 - acc: 1.0000\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0099 - acc: 1.0000\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0097 - acc: 1.0000\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0095 - acc: 1.0000\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0093 - acc: 1.0000\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0091 - acc: 1.0000\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0088 - acc: 1.0000\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0086 - acc: 1.0000\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0083 - acc: 1.0000\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 117/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 168/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 219us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 200/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 251/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 250us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0015 - acc: 1.000 - 0s 344us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 422us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 283/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 1/300\n",
      "64/64 [==============================] - 1s 22ms/step - loss: 4.1630 - acc: 0.0312\n",
      "Epoch 2/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 4.1095 - acc: 0.1719\n",
      "Epoch 3/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 4.0643 - acc: 0.3281\n",
      "Epoch 4/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 4.0206 - acc: 0.4844\n",
      "Epoch 5/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.9757 - acc: 0.6875\n",
      "Epoch 6/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 3.9289 - acc: 0.8125\n",
      "Epoch 7/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.8787 - acc: 0.8906\n",
      "Epoch 8/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 3.8256 - acc: 0.9062\n",
      "Epoch 9/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 3.7688 - acc: 0.9844\n",
      "Epoch 10/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 3.7075 - acc: 1.0000\n",
      "Epoch 11/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.6424 - acc: 1.0000\n",
      "Epoch 12/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 3.5725 - acc: 1.0000\n",
      "Epoch 13/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 3.4962 - acc: 1.0000\n",
      "Epoch 14/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 3.4139 - acc: 1.0000\n",
      "Epoch 15/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 3.3247 - acc: 1.0000\n",
      "Epoch 16/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 3.2293 - acc: 1.0000\n",
      "Epoch 17/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 3.1272 - acc: 1.0000\n",
      "Epoch 18/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 3.0174 - acc: 1.0000\n",
      "Epoch 19/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 2.9004 - acc: 1.0000\n",
      "Epoch 20/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 2.7750 - acc: 1.0000\n",
      "Epoch 21/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 2.6423 - acc: 1.0000\n",
      "Epoch 22/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 2.5020 - acc: 1.0000\n",
      "Epoch 23/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 2.3555 - acc: 1.0000\n",
      "Epoch 24/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 2.2007 - acc: 1.0000\n",
      "Epoch 25/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 2.0408 - acc: 1.0000\n",
      "Epoch 26/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.9478 - acc: 1.000 - 0s 188us/step - loss: 1.8758 - acc: 1.0000\n",
      "Epoch 27/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.7076 - acc: 1.0000\n",
      "Epoch 28/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 1.5370 - acc: 1.0000\n",
      "Epoch 29/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 1.3662 - acc: 1.0000\n",
      "Epoch 30/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 1.1990 - acc: 1.0000\n",
      "Epoch 31/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 1.0370 - acc: 1.0000\n",
      "Epoch 32/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.8832 - acc: 1.0000\n",
      "Epoch 33/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.7432 - acc: 1.0000\n",
      "Epoch 34/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 219us/step - loss: 0.6153 - acc: 1.0000\n",
      "Epoch 35/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.5052 - acc: 1.0000\n",
      "Epoch 36/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.4095 - acc: 1.0000\n",
      "Epoch 37/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.3322 - acc: 1.0000\n",
      "Epoch 38/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.2685 - acc: 1.0000\n",
      "Epoch 39/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.2181 - acc: 1.0000\n",
      "Epoch 40/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.1769 - acc: 1.0000\n",
      "Epoch 41/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.1464 - acc: 1.0000\n",
      "Epoch 42/300\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.1217 - acc: 1.0000\n",
      "Epoch 43/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.1025 - acc: 1.0000\n",
      "Epoch 44/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0872 - acc: 1.0000\n",
      "Epoch 45/300\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0754 - acc: 1.0000\n",
      "Epoch 46/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0658 - acc: 1.0000\n",
      "Epoch 47/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0582 - acc: 1.0000\n",
      "Epoch 48/300\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.0520 - acc: 1.0000\n",
      "Epoch 49/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0468 - acc: 1.0000\n",
      "Epoch 50/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0426 - acc: 1.0000\n",
      "Epoch 51/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0390 - acc: 1.0000\n",
      "Epoch 52/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0360 - acc: 1.0000\n",
      "Epoch 53/300\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0334 - acc: 1.0000\n",
      "Epoch 54/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0312 - acc: 1.0000\n",
      "Epoch 55/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0293 - acc: 1.0000\n",
      "Epoch 56/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0276 - acc: 1.0000\n",
      "Epoch 57/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0261 - acc: 1.0000\n",
      "Epoch 58/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0248 - acc: 1.0000\n",
      "Epoch 59/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0237 - acc: 1.0000\n",
      "Epoch 60/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0226 - acc: 1.0000\n",
      "Epoch 61/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0217 - acc: 1.0000\n",
      "Epoch 62/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0208 - acc: 1.0000\n",
      "Epoch 63/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0205 - acc: 1.000 - 0s 234us/step - loss: 0.0200 - acc: 1.0000\n",
      "Epoch 64/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0193 - acc: 1.0000\n",
      "Epoch 65/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0186 - acc: 1.0000\n",
      "Epoch 66/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0180 - acc: 1.0000\n",
      "Epoch 67/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0174 - acc: 1.0000\n",
      "Epoch 68/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0169 - acc: 1.0000\n",
      "Epoch 69/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0163 - acc: 1.0000\n",
      "Epoch 70/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0159 - acc: 1.0000\n",
      "Epoch 71/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0154 - acc: 1.0000\n",
      "Epoch 72/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0150 - acc: 1.0000\n",
      "Epoch 73/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0146 - acc: 1.000 - 0s 266us/step - loss: 0.0146 - acc: 1.0000\n",
      "Epoch 74/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0142 - acc: 1.0000\n",
      "Epoch 75/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0138 - acc: 1.0000\n",
      "Epoch 76/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0135 - acc: 1.0000\n",
      "Epoch 77/300\n",
      "64/64 [==============================] - 0s 359us/step - loss: 0.0131 - acc: 1.0000\n",
      "Epoch 78/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0128 - acc: 1.0000\n",
      "Epoch 79/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0125 - acc: 1.0000\n",
      "Epoch 80/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0122 - acc: 1.0000\n",
      "Epoch 81/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0119 - acc: 1.0000\n",
      "Epoch 82/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0116 - acc: 1.0000\n",
      "Epoch 83/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0114 - acc: 1.0000\n",
      "Epoch 84/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 85/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 86/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0106 - acc: 1.0000\n",
      "Epoch 87/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 88/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0102 - acc: 1.0000\n",
      "Epoch 89/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 90/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0098 - acc: 1.0000\n",
      "Epoch 91/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0096 - acc: 1.0000\n",
      "Epoch 92/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0094 - acc: 1.0000\n",
      "Epoch 93/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0092 - acc: 1.0000\n",
      "Epoch 94/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 95/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 96/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0087 - acc: 1.0000\n",
      "Epoch 97/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0085 - acc: 1.0000\n",
      "Epoch 98/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0084 - acc: 1.0000\n",
      "Epoch 99/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0082 - acc: 1.0000\n",
      "Epoch 100/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0081 - acc: 1.0000\n",
      "Epoch 101/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 102/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0078 - acc: 1.0000\n",
      "Epoch 103/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 104/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0075 - acc: 1.0000\n",
      "Epoch 105/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 106/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0073 - acc: 1.0000\n",
      "Epoch 107/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 108/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0070 - acc: 1.0000\n",
      "Epoch 109/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0069 - acc: 1.0000\n",
      "Epoch 110/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 111/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 112/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 113/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 114/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 115/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0063 - acc: 1.0000\n",
      "Epoch 116/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 117/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 281us/step - loss: 0.0061 - acc: 1.0000\n",
      "Epoch 118/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 119/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 120/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 121/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 122/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 123/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 124/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 125/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 126/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 127/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 128/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 129/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 130/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 131/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 132/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 133/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 134/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 135/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 136/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 137/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 138/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 139/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 140/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 141/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 142/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 143/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 144/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 145/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 146/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 147/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 148/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 149/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 150/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 151/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 152/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 153/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 154/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 155/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 156/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 157/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 158/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 159/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 160/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 161/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 162/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 163/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 164/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 165/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 166/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 167/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0032 - acc: 1.000 - 0s 250us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 168/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 169/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 170/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 171/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 172/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 173/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 174/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 175/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 176/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 177/300\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 178/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 179/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 180/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 181/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 182/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 183/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 184/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 185/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 186/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 187/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 188/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 189/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 190/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 191/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 192/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 193/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 194/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 195/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 196/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 197/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 198/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 199/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 200/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 281us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 201/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 202/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 203/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 204/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 205/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 206/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 207/300\n",
      "64/64 [==============================] - 0s 313us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 208/300\n",
      "64/64 [==============================] - 0s 406us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 209/300\n",
      "64/64 [==============================] - 0s 344us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 210/300\n",
      "64/64 [==============================] - 0s 328us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 211/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 212/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 213/300\n",
      "64/64 [==============================] - 0s 391us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 214/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 215/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 216/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 217/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 218/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 219/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 220/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 221/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 222/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 223/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 224/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 225/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 226/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 227/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 228/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 229/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 230/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 231/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 232/300\n",
      "64/64 [==============================] - 0s 297us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 233/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 234/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 235/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 236/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 237/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 238/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 239/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 240/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 241/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 242/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 243/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 244/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0016 - acc: 1.000 - 0s 219us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 245/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 246/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 247/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 248/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 249/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 250/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 251/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 252/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 253/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 254/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 255/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 256/300\n",
      "64/64 [==============================] - 0s 266us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 257/300\n",
      "64/64 [==============================] - 0s 828us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 258/300\n",
      "64/64 [==============================] - 0s 281us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 259/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 260/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 261/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 262/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 263/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 264/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 265/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 266/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 267/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 268/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 269/300\n",
      "64/64 [==============================] - 0s 156us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 270/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 271/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 272/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 273/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 274/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 275/300\n",
      "64/64 [==============================] - 0s 172us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 276/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 277/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 278/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 279/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 280/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 281/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 282/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 283/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 0s 172us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 284/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 285/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 286/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 287/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 288/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 289/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 290/300\n",
      "64/64 [==============================] - 0s 250us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 291/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 292/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 293/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 294/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 295/300\n",
      "64/64 [==============================] - 0s 188us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 296/300\n",
      "64/64 [==============================] - 0s 219us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 297/300\n",
      "64/64 [==============================] - 0s 203us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 298/300\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.0011 - acc: 1.000 - 0s 266us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 299/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 300/300\n",
      "64/64 [==============================] - 0s 234us/step - loss: 0.0011 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b206dd8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the training output will be the category corresponding to the position of the pixel in the mangled image\n",
    "y_train = [np.where(Mmang_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train = to_categorical(y_train, nbpix**2)\n",
    "\n",
    "# or the position of the pixel in the corrected image\n",
    "y_train_cor = [np.where(Mstar_tab[ii,:]==1)[0].item(0) for ii in idx]\n",
    "y_train_cor = to_categorical(y_train_cor, nbpix**2)\n",
    "\n",
    "node_nb = min(max(100, 5*nbpix**2), 300)\n",
    "epoch_nb = min(max(100, 5*nbpix**2), 300)\n",
    "\n",
    "# creating the models\n",
    "model_mangler = Sequential()\n",
    "model_mangler.add(Dense(node_nb, activation='relu', input_dim=nbpix**2))\n",
    "model_mangler.add(Dense(node_nb, activation='relu'))\n",
    "model_mangler.add(Dense(nbpix**2, activation='softmax'))\n",
    "# Inversion strategy doesnt work very well...\n",
    "# we are going to try using another model, trained on the corrected input.\n",
    "model_corrector = Sequential()\n",
    "model_corrector.add(Dense(node_nb, activation='relu', input_dim=nbpix**2))\n",
    "model_corrector.add(Dense(node_nb, activation='relu'))\n",
    "model_corrector.add(Dense(nbpix**2, activation='softmax'))\n",
    "\n",
    "# Compile the models\n",
    "model_mangler.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "model_corrector.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# train the model \"mangler\"\n",
    "model_mangler.fit( X_train,\n",
    "    y_train,\n",
    "    epochs=epoch_nb,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# train the corrected input model\n",
    "model_corrector.fit( X_train,\n",
    "    y_train_cor,\n",
    "    epochs=epoch_nb,\n",
    "    shuffle=True,\n",
    "    verbose=1\n",
    ")    \n",
    "\n",
    "# model_mangler.summary()\n",
    "# model_corrector.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    }
   ],
   "source": [
    "print(5*nbpix**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the models\n",
    "# print()\n",
    "mang_name = os.path.join(r\"webapp\\models\", f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "cor_name = os.path.join(r\"webapp\\models\", f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")\n",
    "\n",
    "model_mangler.save(mang_name)\n",
    "model_corrector.save(cor_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webapp\\models\\translation_full_mangler_4x4.h5\n"
     ]
    }
   ],
   "source": [
    "# Apply the models to an existing image\n",
    "\n",
    "\n",
    "\n",
    "# Load the saved models\n",
    "model_mangler = load_model(f\"{transform_type}_{training_type}_mangler_{nbpix}x{nbpix}.h5\")\n",
    "model_corrector = load_model(f\"{transform_type}_{training_type}_corrector_{nbpix}x{nbpix}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mreal = create_door_img(nbpix) \n",
    "cut = 0.5\n",
    "Mreal = np.random.choice([0, 1], size=(nbpix,nbpix), p=[ 1-cut, cut])\n",
    "# Mreal_split = split_matrix(Mreal)\n",
    "\n",
    "# Predict the mangled image based on the real one\n",
    "Mmang_ml = perform_prediction(Mreal,model_mangler ) # predict_mangler(Mreal)\n",
    "# Predict the corrected input based on the real image\n",
    "Mcor_ml = perform_prediction(Mreal, model_corrector)# predict_corrector(Mreal)\n",
    "# Prediction of the output from the corrected input\n",
    "Mout_ml = perform_prediction(np.round(Mcor_ml), model_mangler)\n",
    "# plot the results\n",
    "# vis_matrices(Mreal, Mmang_ml,Mcor_ml, Mout_ml)\n",
    "if transform_type == \"translation\":\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, translate2left(Mcor_ml))\n",
    "elif transform_type == \"rotation\":\n",
    "    print(Mcor_ml)\n",
    "    vis_matrices(Mreal, Mmang_ml,Mcor_ml, rot90ccw(Mcor_ml))\n",
    "    \n",
    "# print(transform_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrayToList(arr):\n",
    "    return [ii.item() for ii in arr.reshape((arr.size,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Mcor': [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1], 'Mout': array([[0., 0., 1., 1.],\n",
      "       [0., 1., 0., 0.],\n",
      "       [1., 0., 0., 0.],\n",
      "       [1., 1., 0., 0.]])}\n"
     ]
    }
   ],
   "source": [
    "mang_matrices = {}\n",
    "mang_matrices[\"Mcor\"] = arrayToList(Mreal)\n",
    "\n",
    "if transform_type == \"translation\":\n",
    "    mang_matrices[\"Mout\"] = translate2right(np.asarray(mang_matrices[\"Mcor\"]).reshape(nbpix,nbpix))\n",
    "elif transform_type == \"rotation\":\n",
    "    mang_matrices[\"Mout\"] = rot90cw(np.asarray(mang_matrices[\"Mcor\"]).reshape(nbpix,nbpix))\n",
    "\n",
    "# mang_matrices = {\"Mout\": arrayToList(Mmang_ml)}\n",
    "print(mang_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform into a list\n",
    "mat_list = [ii.item() for ii in Mreal.reshape((nbpix**2,1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Mreal.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  6,  8, 10, 12, 14])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(4,16,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 8, 10, 12, 14]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrayToList(np.arange(4,16,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "rotation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decoding the matrix from the route url\n",
    "import re\n",
    "nbpixTransformMat = \"4rotation1101110100010001\"\n",
    "nbpix = int(re.search(r'\\d+', nbpixTransformMat).group())\n",
    "print(nbpix)\n",
    "transform_type = ''.join([i for i in nbpixTransformMat if not i.isdigit()])   \n",
    "print(transform_type)\n",
    "training_type = \"full\" # for now we only use fully trained models\n",
    "\n",
    "mat = nbpixTransformMat[-nbpix**2:]\n",
    "\n",
    "input_values = np.asarray([int(mm) for mm in nbpixTransformMat[-nbpix**2:]])\n",
    "input_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output from the corrected input\n",
    "\n",
    "def arrayToList(arr):\n",
    "    \"\"\" Transform a np.array of any size into a flat list \"\"\"\n",
    "    return [ii.item() for ii in arr.reshape((arr.size,1))]\n",
    "def translate2right2(mat, nbpix):\n",
    "    P,Pstar = create_PPstar_translation(nbpix)\n",
    "    mat = np.asarray(mat).reshape(nbpix,nbpix)\n",
    "\n",
    "    return mat@Pstar   \n",
    "\n",
    "def rot90cw2(mat, nbpix):\n",
    "    \"\"\" Rotate an n by n matrix 90 deg counter clock wise\"\"\"\n",
    "\n",
    "    mat = np.asarray(mat).reshape(nbpix,nbpix)\n",
    "    print(mat)\n",
    "    print(mat.shape)\n",
    "    \n",
    "    # rotation matrix\n",
    "    rot = np.array([[0, -1],\n",
    "               [1,0]])\n",
    "    # matrix coordinates\n",
    "    coord = [i for i in np.ndindex(mat.shape)]\n",
    "    nbp = mat.shape[0]    \n",
    "    # initialisations\n",
    "    coord_rot = []\n",
    "    mat_rot = np.zeros((mat.shape))    \n",
    "    # Apply the transformation on each pixel's coordinates\n",
    "    print(len(coord))\n",
    "    for ii in range(0,len(coord)):\n",
    "        print(ii)\n",
    "        # apply the rotation to the coordinate vector\n",
    "        coord_rot.append(coord[ii]@rot)\n",
    "        # reverse the row axis\n",
    "        coord_rot[ii][0] += nbp-1\n",
    "        # transform back into a tuple\n",
    "        coord_rot[ii] = tuple(coord_rot[ii])   \n",
    "        # fill up the rotated matrix\n",
    "        mat_rot[coord_rot[ii]] = mat[coord[ii]]        \n",
    "    \n",
    "    return mat_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1]\n",
      " [1 1 0 1]\n",
      " [0 0 0 1]\n",
      " [0 0 0 1]]\n",
      "(4, 4)\n",
      "16\n",
      "0\n",
      "1\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ea136f3fb7ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmang_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Mout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtranslate2right2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmang_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Mcor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnbpix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0mtransform_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"rotation\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mmang_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Mout\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrot90cw2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmang_matrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Mcor\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbpix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmang_matrices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"Mmang\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marrayToList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMmang_ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-05ee57493c67>\u001b[0m in \u001b[0;36mrot90cw2\u001b[1;34m(mat, nbpix)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mcoord_rot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoord_rot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# fill up the rotated matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mmat_rot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoord_rot\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmat_rot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
